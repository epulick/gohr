{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, glob\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from itertools import combinations\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from helper_funcs import bucket_remap,process_board,ax_err_plots_player\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "def get_shape(pd,reference):\n",
    "    piece = pd['piece']\n",
    "    return reference[piece['shape']]\n",
    "\n",
    "def get_color(pd,reference):\n",
    "    piece = pd['piece']\n",
    "    return reference[piece['color']]\n",
    "\n",
    "# zero-indexed (row/col/cell normally 1 indexed)\n",
    "def get_row(pd,reference):\n",
    "    piece = pd['piece']\n",
    "    return piece['y']-1+reference\n",
    "\n",
    "# zero-indexed (row/col/cell normally 1 indexed)\n",
    "def get_col(pd,reference):\n",
    "    piece = pd['piece']\n",
    "    return piece['x']-1+reference\n",
    "\n",
    "# zero-indexed (row/col/cell normally 1 indexed)\n",
    "def get_cell(pd,reference):\n",
    "    piece = pd['piece']\n",
    "    return (piece['y']-1)*6+piece['x']-1\n",
    "\n",
    "# zero-indexed (buckets always are)\n",
    "def get_bucket(pd,reference):\n",
    "    buckets = list(pd['reduced_move_list'])[-reference:]\n",
    "    bucket_id = {0:0,1:1,2:2,3:3,None:4}\n",
    "    bucket_tuple = tuple([bucket_id[x] for x in buckets])\n",
    "    return np.ravel_multi_index(bucket_tuple,tuple([5 for x in range(reference)]))\n",
    "\n",
    "def get_quadrant(pd,reference):\n",
    "    cell = get_cell(pd,None)+1\n",
    "    if cell in [1,2,3,7,8,9,13,14,15]:\n",
    "        return 0\n",
    "    elif cell in [4,5,6,10,11,12,16,17,18]:\n",
    "        return 1\n",
    "    elif cell in [19,20,21,25,26,27,31,32,33]:\n",
    "        return 2\n",
    "    elif cell in [22,23,24,28,29,30,34,35,36]:\n",
    "        return 3\n",
    "    else:\n",
    "        print(\"error calculating quadrant\")\n",
    "        breakpoint()\n",
    "\n",
    "class ProcessedEnv():\n",
    "    def __init__(self,args):\n",
    "        self.model_features = args['MODEL_FEATURES']\n",
    "        self.shape_id = {'STAR':0, 'SQUARE':1, 'TRIANGLE':2, 'CIRCLE':3}\n",
    "        self.color_id = {'RED':0, 'BLUE':1, 'GREEN':2, 'YELLOW':3}\n",
    "        # shape_order = ['TRIANGLE','CIRCLE','SQUARE','STAR']\n",
    "        # color_order = ['RED','BLUE','YELLOW','GREEN']\n",
    "        # Sanity check on feature count input\n",
    "        if len(self.model_features)<1:\n",
    "            print(\"Did you forget to add model features?\")\n",
    "            breakpoint()\n",
    "\n",
    "        # Store all information about how to process each feature in following dictionary\n",
    "        self.feature_info = {'shape':{'input_space':4,'func':get_shape,'reference':self.shape_id},\n",
    "                       'color':{'input_space':4, 'func':get_color,'reference':self.color_id},\n",
    "                       'move_row':{'input_space':6, 'func':get_row,'reference':1},\n",
    "                       'move_col':{'input_space':6, 'func':get_col,'reference':1},\n",
    "                       'row':{'input_space':6, 'func':get_row,'reference':0},\n",
    "                       'col':{'input_space':6, 'func':get_col,'reference':0},\n",
    "                       'quadrant':{'input_space':4,'func':get_quadrant,'reference':None},\n",
    "                       'cell':{'input_space':36,'func':get_cell,'reference':None},\n",
    "                       'bucket1':{'input_space':5,'func':get_bucket,'reference':1},\n",
    "                       'bucket2':{'input_space':5**2,'func':get_bucket,'reference':2},\n",
    "                       'bucket3':{'input_space':5**3,'func':get_bucket,'reference':3},\n",
    "                       'bucket4':{'input_space':5**4,'func':get_bucket,'reference':4}}\n",
    "        \n",
    "        # Set up lists for storing past actions and board states\n",
    "        self.list_memory = 5\n",
    "        self.full_move_list = deque([None for x in range(self.list_memory)],maxlen=self.list_memory)\n",
    "        self.reduced_move_list = deque([None for x in range(self.list_memory)],maxlen=self.list_memory)\n",
    "        self.board_list = deque([None for x in range(self.list_memory)],maxlen=self.list_memory)\n",
    "\n",
    "    def process_row(self,row):\n",
    "        # Extract the x,y position of chosen piece, the chosen bucket, and current board\n",
    "        x = row['x']\n",
    "        y = row['y']\n",
    "        bucket = row['bucket']\n",
    "        board = row['proc_board']\n",
    "        self.process_features(x,y,bucket,board)\n",
    "\n",
    "    def process_features(self,x,y,bucket,board):\n",
    "        # List of features, each entry is a dict describing the piece attributes\n",
    "        self.feature_list = []\n",
    "        self.reduced_move_list.append(bucket)\n",
    "        self.full_move_list.append(np.nan)\n",
    "        self.board_list.append(board)\n",
    "        self.chosen_piece_features=None\n",
    "\n",
    "        if len(board)>0:\n",
    "            for piece in board:\n",
    "                # Initialize\n",
    "                feature_vals = dict.fromkeys(self.model_features)\n",
    "                feature_vals['move_row']=None\n",
    "                feature_vals['move_col']=None\n",
    "                \n",
    "                # Create standardized processing dictionary for feature processing functions\n",
    "                processing_dict = {'piece':piece,'full_move_list':self.full_move_list,'reduced_move_list':self.reduced_move_list,'board_list':self.board_list}\n",
    "                # Extract the 1-indexed row and column for each piece\n",
    "                feature_vals['move_row'] = get_row(processing_dict,1)\n",
    "                feature_vals['move_col'] = get_col(processing_dict,1)\n",
    "                # Loop over all features used in the model and process the corresponding state values\n",
    "                for feat in self.model_features:\n",
    "                    func = self.feature_info[feat]['func']\n",
    "                    ref = self.feature_info[feat]['reference']\n",
    "                    feature_vals[feat]=func(processing_dict,ref)\n",
    "                # Append the feature values dictionary to a list (describing all pieces on the board)\n",
    "                self.feature_list.append(feature_vals)\n",
    "                # If the current piece corresponds to the piece chosen by the user, store the dictionary for easy access by the models\n",
    "                if feature_vals['move_col']==x and feature_vals['move_row']==y:\n",
    "                    self.chosen_piece_features = feature_vals\n",
    "\n",
    "    # def get_feature(self):\n",
    "    #     self.process_features()\n",
    "    #     return self.feature_list\n",
    "    \n",
    "    def return_feature(self,feat):\n",
    "        return {'move_row':self.feature_vals['move_row'],'move_col':self.feature_vals['move_col'],'features':self.feature_vals[feat]}\n",
    "\n",
    "    def calc_dim(self,feat_arr):\n",
    "        dims = tuple(self.feature_info[feat]['input_space'] for feat in feat_arr)\n",
    "        return dims\n",
    "\n",
    "class human_bandit_model():\n",
    "    def __init__(self,feats,dims,env):\n",
    "        # Connect the environment to this model\n",
    "        self.env = env\n",
    "        # Reward scheme\n",
    "        self.init_q_value = 0\n",
    "        self.correct = 1\n",
    "        self.incorrect = -1\n",
    "\n",
    "        # Establish rolling memory queues for each model with configurable memory\n",
    "        self.memory_horizon = 10\n",
    "        self.memory=deque([],self.memory_horizon)\n",
    "\n",
    "        # Set up model features\n",
    "        self.feats = feats\n",
    "        self.feat_dims = dims\n",
    "        self.in_dim, self.out_dim = np.prod(self.feat_dims), 4\n",
    "        self.q_values = np.full((self.in_dim,self.out_dim),self.init_q_value,dtype=np.int8)\n",
    "\n",
    "        # Initialize model credibility\n",
    "        self.credibility_log = deque([],maxlen=10)\n",
    "        self.credibility=sum(self.credibility_log)\n",
    "    \n",
    "    def return_credibility(self):\n",
    "        return self.credibility\n",
    "\n",
    "    def return_qvals(self):\n",
    "        return np.copy(self.q_values)\n",
    "        \n",
    "    # Process the model's memory into the current rolling q-table\n",
    "    def proc_qtable(self):\n",
    "        # Reset the q-table\n",
    "        self.q_values = np.full((self.in_dim,self.out_dim),self.init_q_value,dtype=np.int8)\n",
    "\n",
    "        # Iterate over memory tuples and update q-table\n",
    "        for (state,action,reward) in self.memory:\n",
    "            self.q_values[state,action]=reward\n",
    "\n",
    "    # Process credibility \n",
    "    def proc_cred(self,state,action):\n",
    "        # Array of q-values associated with the chosen piece\n",
    "        piece_q = self.q_values[state,:]\n",
    "        # Q-value of the selected action for the chosen piece\n",
    "        chosen_q = self.q_values[state,action]\n",
    "        self.move_type=None\n",
    "\n",
    "        # Credibility model\n",
    "        # If the action taken is known to be correct\n",
    "        if chosen_q==self.correct:\n",
    "            self.credibility_log.append(2/self.in_dim)\n",
    "            self.move_type=4\n",
    "        # If player selects an exploratory action for a piece with no known correct moves\n",
    "        elif chosen_q==self.init_q_value and piece_q.max()==self.init_q_value:\n",
    "            self.credibility_log.append(1/self.in_dim)\n",
    "            self.move_type=3\n",
    "        # Player selects an exploratory move for a piece with known correct move\n",
    "        elif chosen_q==self.init_q_value and piece_q.max()==self.correct:\n",
    "            self.credibility_log.append(-1/self.in_dim)\n",
    "            self.move_type=2\n",
    "        # Player selects a move known to be incorrect\n",
    "        elif chosen_q==self.incorrect:\n",
    "            self.credibility_log.append(-3/self.in_dim)\n",
    "            self.move_type=1\n",
    "        else:\n",
    "            print(\"ERROR: credibility processing failed to catch case\")\n",
    "\n",
    "        self.credibility=sum(self.credibility_log)\n",
    "    # Process the current row of the human's experience\n",
    "    def proc_row(self):\n",
    "        states = tuple(self.env.chosen_piece_features[feat] for feat in self.feats)\n",
    "        state = np.ravel_multi_index(states,self.feat_dims)\n",
    "        return state\n",
    "        \n",
    "    def update(self,state,action,reward):\n",
    "        # Process credibility (score based on the action's relation to the model's q-table)\n",
    "        self.proc_cred(state,action)\n",
    "        # Add tuple to memory\n",
    "        self.memory.append((state,action,reward))\n",
    "        # Process the model's q-table based on the current rolling memory\n",
    "        self.proc_qtable()\n",
    "\n",
    "class hl_model():\n",
    "   \n",
    "    def __init__(self,exp_dir,rules):\n",
    "        # Gather data associated with experiment\n",
    "        self.data_import(exp_dir,rules)\n",
    "        \n",
    "        # Model configuration\n",
    "        # List of features to be used for the underlying models\n",
    "        self.model_features = ['shape','color','row','col','quadrant','cell','bucket1','bucket2']\n",
    "        self.args={}\n",
    "        self.args['MODEL_FEATURES'] = self.model_features\n",
    "        # Types of feature combinations to be used (1->unary, 2->binary combinations, etc.)\n",
    "        self.combination_types = [1]\n",
    "        self.env = ProcessedEnv(self.args)\n",
    "\n",
    "    # Import relevant player files\n",
    "    def data_import(self,exp_dir,tested_rules):\n",
    "        # Initialize list for concatenating player records\n",
    "        df_list =[]\n",
    "        # Create a list containing all csv's in the given directory\n",
    "        csv_list = glob.glob(\"**/*.csv\",root_dir=exp_dir, recursive=True)\n",
    "        #print(csv_list)\n",
    "        # Loop over the files\n",
    "        for item in csv_list:\n",
    "            # Construct the import path and read data\n",
    "            import_path = os.path.join(exp_dir,item)\n",
    "            print(import_path)\n",
    "            df = pd.read_csv(import_path)\n",
    "            #display(df)\n",
    "            # Only work with data from a player's first encounter with the game\n",
    "            series_num = df['seriesNo'].unique()[0]\n",
    "            if series_num != 0:\n",
    "                print(\"didn't meet series req\")\n",
    "                continue\n",
    "\n",
    "            # Check the contained rules for multiple rules/players\n",
    "            rules = df[\"#ruleSetName\"].unique()\n",
    "            player = df['playerId'].unique()\n",
    "            if len(player)>1:\n",
    "                print('------ERROR-----')\n",
    "                print(\"File contains more than one player: \",import_path)\n",
    "                print('----------------')\n",
    "                break\n",
    "            if len(rules)>1:\n",
    "                print('------ERROR-----')\n",
    "                print(\"Error reading the rules, multiple rules in file: \",import_path)\n",
    "                print('----------------')\n",
    "                break\n",
    "            \n",
    "            if player[0][0:2]!='ML' and ('testing' in player[0] or 'A_WORKER_ID' in player[0] or \"Aria\" in player[0] or player[0][0]!=\"A\"):\n",
    "                print(\"player name issues\")\n",
    "                continue\n",
    "\n",
    "            if df.orderInSeries.max()<2:\n",
    "                print(\"orderinseries issue\")\n",
    "                continue\n",
    "            # if rules[0].split(\"/\")[-1] not in tested_rules:\n",
    "            #     continue\n",
    "\n",
    "            # Get rid of finger slips (assumed when the player grabs a movable piece but misses putting it into a bucket)\n",
    "            finger_slips = (df.code == 0)&(df.bx.isna())&(df.by.isna())\n",
    "            df = df[~finger_slips]\n",
    "            # Reset index immediately\n",
    "            df.reset_index(drop=True,inplace=True)\n",
    "            # Set the move number to be the corrected index\n",
    "            df['move']=df.index\n",
    "            # Simplify output code to errors\n",
    "            df['err']=df.apply(lambda row: 0 if row.code==0 else 1, axis=1)\n",
    "            df['cumulative_err']=df.err.cumsum()\n",
    "\n",
    "            # Add processed columns\n",
    "            df['bucket']=df.copy().apply(lambda x: bucket_remap(x['by'],x['bx']),axis=1)\n",
    "            df['proc_board']=df.copy().apply(lambda x: process_board(x['board']),axis=1)\n",
    "            #df[['shape','color','shape_ind','color_ind','id','cell','cell_ind']]=df.copy().apply(lambda x: get_attributes(x['proc_board'],x['y'],x['x']),axis=1,result_type='expand')\n",
    "            # df[['shape0','shape1','shape2','shape3','color0','color1','color2','color3',\n",
    "            #     'c1','c2','c3','c4','c5','c6','c7','c8','c9','c10','c11','c12',\n",
    "            #     'c13','c14','c15','c16','c17','c18','c19','c20','c21','c22','c23','c24',\n",
    "            #     'c25','c26','c27','c28','c29','c30','c31','c32','c33','c34','c35','c36']] = df.copy().apply(lambda x:calc_availability(x['proc_board'],shape_order,color_order),axis=1,result_type='expand')\n",
    "\n",
    "            # Column cleanup\n",
    "            df.rename(columns = {'orderInSeries':'episode','playerId':'player','#ruleSetName':'rule'},inplace=True)\n",
    "            if 'precedingRules' in df:\n",
    "                df.drop(columns=['seriesNo','precedingRules','timestamp','episodeId',\n",
    "                                'experimentPlan','trialListId','board','p0','by','bx',\n",
    "                                'moveNo'],axis=1,inplace=True)\n",
    "            df_list.append(df)\n",
    "\n",
    "            # Set for debugging\n",
    "            self.debug_df = df.copy()\n",
    "\n",
    "        # Concatenate into a single dataframe\n",
    "        self.main_df = pd.concat(df_list,ignore_index=True)\n",
    "\n",
    "    def init_models(self):\n",
    "        # Initialize a list of all feature combinations to be used and populate iteratively using the combinations tool\n",
    "        # Result will be a list of tuples of feature strings\n",
    "        self.feature_combinations = []\n",
    "        for r in self.combination_types:\n",
    "            self.feature_combinations.extend(combinations(self.model_features,r))\n",
    "        \n",
    "        # Construct a list of models, each of which is constructed with a feature tuple and a dimension tuple\n",
    "        self.models=[human_bandit_model(feat_arr,self.env.calc_dim(feat_arr),self.env) for feat_arr in self.feature_combinations]\n",
    "\n",
    "    # Debugging utility for presenting models and associated q values\n",
    "    def present_models(self):\n",
    "        for model in self.models:\n",
    "            print(model.feats,model.feat_dims)\n",
    "            print(model.q_values)\n",
    "\n",
    "    def player_train(self,player):\n",
    "        # Train on a player's experience\n",
    "        df = self.main_df.query(\"player==@player\").copy()\n",
    "        \n",
    "        cred_df_list = []\n",
    "        move_type_list=[]\n",
    "        # Initialize models for this player\n",
    "        self.init_models()\n",
    "\n",
    "        # Loop over the rows of this player's experience\n",
    "        for index,row in df.iterrows():\n",
    "            # PREDICTION STAGE\n",
    "            # Establish list of credibilities\n",
    "            credibilities = [model.return_credibility() for model in self.models]\n",
    "            # Find the best model (via the index)\n",
    "            best = np.argmax(credibilities)\n",
    "            best_model = self.models[best]\n",
    "            \n",
    "            # PROCESSING STAGE\n",
    "            # Process row through the environment module\n",
    "            self.env.process_row(row)\n",
    "            # Action is determined\n",
    "            action=row.bucket\n",
    "            # Logging credibilities\n",
    "            creds = {}\n",
    "            move_types={}\n",
    "            # Update each model\n",
    "            for model in self.models:\n",
    "                # Get the raveled state for this move (prepared during env.process_row)\n",
    "                state=model.proc_row()\n",
    "                # Get the reward value\n",
    "                reward=model.incorrect if row.err else model.correct\n",
    "                # Update the model credibility and q-table\n",
    "                model.update(state,action,reward)\n",
    "                # Log the model credibility\n",
    "                creds[model.feats]=model.return_credibility()\n",
    "\n",
    "            cred_df_step = pd.DataFrame([creds])\n",
    "            cred_df_list.append(cred_df_step)\n",
    "         \n",
    "            # Gather move types\n",
    "            credibilities = [(model,model.return_credibility()) for model in self.models]\n",
    "            sorted_cred = sorted(credibilities, key=lambda x: x[1],reverse=True)\n",
    "\n",
    "            for i,mod in enumerate(sorted_cred[0:2]):\n",
    "                model_rank = i+1\n",
    "                move_types[model_rank]=mod[0].move_type\n",
    "            move_types[-1]=sorted_cred[-1][0].move_type\n",
    "            move_types[-2]=sorted_cred[-2][0].move_type\n",
    "            move_types_df_step = pd.DataFrame([move_types])\n",
    "            move_type_list.append(move_types_df_step)\n",
    "\n",
    "        cred_df = pd.concat(cred_df_list,ignore_index=True)\n",
    "        cred_df['move']=cred_df.copy().index+1\n",
    "        move_type_df = pd.concat(move_type_list,ignore_index=True)\n",
    "        move_type_df['move']=move_type_df.copy().index+1\n",
    "\n",
    "        #display(cred_df)\n",
    "        for model in self.models:\n",
    "            pass\n",
    "            #print(model.feats,model.return_credibility())\n",
    "\n",
    "        self.move_type_df = move_type_df\n",
    "        return cred_df,move_type_df\n",
    "            \n",
    "    def experiment_train(self):\n",
    "        # Establish player list\n",
    "        players = self.main_df.player.unique()\n",
    "        print(players)\n",
    "        log_dir = \"/Users/eric/repos/gohr/bandit/human_learning/plots\"\n",
    "        complete_store=PdfPages(os.path.join(log_dir,\"synthetic_complete.pdf\"))\n",
    "        # Loop over the players\n",
    "        for player in players:\n",
    "            print(player)\n",
    "            #print(\"Experience for player {}\".format(player))\n",
    "            creds,move_types = self.player_train(player)\n",
    "            melted_cred = pd.melt(creds,['move'])\n",
    "            melted_moves = pd.melt(move_types,['move'])\n",
    "            \n",
    "            player_df = self.main_df.query(\"player==@player\").copy()\n",
    "            rule = player_df.rule.unique()[0].split('/')[-1]\n",
    "            fig = plt.figure(layout='constrained', figsize=(25,14))\n",
    "            subfigs = fig.subfigures(1, 2)\n",
    "            ax = subfigs[0].subplots(2,1)\n",
    "            #sns.lineplot(ax=ax,data=player_df,x='move',y='cumulative_err')\n",
    "            ax_err_plots_player(ax[0],player_df)\n",
    "            sns.lineplot(ax=ax[1],data=melted_cred,x='move',y='value',hue='variable')\n",
    "            ax[1].set_xlabel(\"Move\")\n",
    "            ax[1].set_ylabel(\"Credibility\")\n",
    "\n",
    "            ax = subfigs[1].subplots(4,1)\n",
    "            custom_palette = {1:'red',2:'orange',3:'limegreen',4:'forestgreen'}\n",
    "            for j in [1,2]:\n",
    "                ind = j-1\n",
    "                sns.scatterplot(ax=ax[ind],data=melted_moves.query(\"variable==@j\"),x='move',y='value',hue='value',palette=custom_palette,legend=False)\n",
    "                ax[ind].set_title(\"Model Rank {}\".format(j))\n",
    "                ax[ind].set_ylim([0.5,4.5])\n",
    "                ax[ind].set_yticks([1,2,3,4])\n",
    "                ax[ind].set_xlabel(\"Move\")\n",
    "                ax[ind].set_ylabel(\"Move Type\")\n",
    "            sns.scatterplot(ax=ax[2],data=melted_moves.query(\"variable==-2\"),x='move',y='value',hue='value',palette=custom_palette,legend=False)\n",
    "            sns.scatterplot(ax=ax[3],data=melted_moves.query(\"variable==-1\"),x='move',y='value',hue='value',palette=custom_palette,legend=False)\n",
    "            ax[2].set_title(\"Model Rank: -2\")\n",
    "            ax[3].set_title(\"Model Rank: -1\")\n",
    "            ax[2].set_ylim([0.5,4.5])\n",
    "            ax[2].set_yticks([1,2,3,4])\n",
    "            ax[2].set_xlabel(\"Move\")\n",
    "            ax[2].set_ylabel(\"Move Type\")\n",
    "            ax[3].set_ylim([0.5,4.5])\n",
    "            ax[3].set_yticks([1,2,3,4])\n",
    "            ax[3].set_xlabel(\"Move\")\n",
    "            ax[3].set_ylabel(\"Move Type\")\n",
    "            # Title, close, and store\n",
    "            fig.suptitle(\"Player: \"+str(player)+\", Rule: \"+str(rule)+\"\\n\")\n",
    "            plt.close(fig)\n",
    "            complete_store.savefig(fig,bbox_inches='tight',facecolor='w')\n",
    "        self.melted_moves = melted_moves\n",
    "        # Close pdfpages\n",
    "        complete_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A23G1L7KYHK9F2.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A7VA2Y4H6U31O.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A2LU7CL50XLYJO.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A1ZD9SJXQ9C6EW.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A25UQ2WHJ5AIEQ.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A3POD149IG0DIW.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A1GNMI2HPRMWEY.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A2B153AHPWHLH1.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A3CT8UTPVYUL04.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A1SNC8UL8YFRH5.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A3INEKAD86IRQC.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/AUZNL6ARA1UEC.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A1WMYG2J33KTTI.split-transcripts.csv\n",
      "orderinseries issue\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/AM478J9YCDX8.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A2PIFMM4Q2I9ZS.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/ep17_12_11_22.split-transcripts.csv\n",
      "player name issues\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A1N93G08WP4XH7.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A2UO74BT2MCREJ.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A2GW4MHR7P2F8L.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A6U2C66WQ7QQN.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A80WPJSYIU9LT.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A3BU32QBDM7DAM.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/AMPR904VJJFZY.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/APWB9BS1SONNS.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A1M5XH28HSUQ6N.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/AET9E1TW11BMX.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A1XR9O41KP6P3H.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A3M7KQYOMDA2MA.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A2BW6WD7LZ9EGV.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A1AZTE5W2MF1TU.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/ACXEEM1J2SGP7.split-transcripts.csv\n",
      "/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua/A2L18Q7871EONK.split-transcripts.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rule</th>\n",
       "      <th>player</th>\n",
       "      <th>episode</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>code</th>\n",
       "      <th>move</th>\n",
       "      <th>err</th>\n",
       "      <th>cumulative_err</th>\n",
       "      <th>bucket</th>\n",
       "      <th>proc_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ep/1_1_color_3m_cua</td>\n",
       "      <td>A23G1L7KYHK9F2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 13438, 'color': 'RED', 'shape': 'CIRCL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ep/1_1_color_3m_cua</td>\n",
       "      <td>A23G1L7KYHK9F2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[{'id': 13438, 'color': 'RED', 'shape': 'CIRCL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ep/1_1_color_3m_cua</td>\n",
       "      <td>A23G1L7KYHK9F2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'id': 13439, 'color': 'YELLOW', 'shape': 'SQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ep/1_1_color_3m_cua</td>\n",
       "      <td>A23G1L7KYHK9F2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'id': 13439, 'color': 'YELLOW', 'shape': 'SQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ep/1_1_color_3m_cua</td>\n",
       "      <td>A23G1L7KYHK9F2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 13439, 'color': 'YELLOW', 'shape': 'SQ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rule          player  episode  y  x  code  move  err  \\\n",
       "0  ep/1_1_color_3m_cua  A23G1L7KYHK9F2        0  6  1     0     0    0   \n",
       "1  ep/1_1_color_3m_cua  A23G1L7KYHK9F2        0  1  1     0     1    0   \n",
       "2  ep/1_1_color_3m_cua  A23G1L7KYHK9F2        0  1  5     4     2    1   \n",
       "3  ep/1_1_color_3m_cua  A23G1L7KYHK9F2        0  4  5     0     3    0   \n",
       "4  ep/1_1_color_3m_cua  A23G1L7KYHK9F2        0  1  5     0     4    0   \n",
       "\n",
       "   cumulative_err  bucket                                         proc_board  \n",
       "0               0       0  [{'id': 13438, 'color': 'RED', 'shape': 'CIRCL...  \n",
       "1               0       3  [{'id': 13438, 'color': 'RED', 'shape': 'CIRCL...  \n",
       "2               1       2  [{'id': 13439, 'color': 'YELLOW', 'shape': 'SQ...  \n",
       "3               1       1  [{'id': 13439, 'color': 'YELLOW', 'shape': 'SQ...  \n",
       "4               1       0  [{'id': 13439, 'color': 'YELLOW', 'shape': 'SQ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_path = \"/Users/eric/data_analysis/ambiguity4/ep/1_1_color_3m_cua\"\n",
    "#exp_path = \"/Users/eric/repos/gohr/bandit/outputs/data_generator/shape\"\n",
    "rules = [\"1_1_color_4m\",\"1_2_color_4m\",\"1_1_color_3m_cua\",\"1_1_shape_4m\",\"1_2_shape_4m\",\"1_1_shape_3m_cua\",\"quadrantNearby\",\"quadrantNearbyTwoFree\"]\n",
    "model = hl_model(exp_path,rules)\n",
    "model.main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ML_shape']\n",
      "ML_shape\n",
      "0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'x'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/eric/repos/gohr/bandit/human_learning/debugging.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/eric/repos/gohr/bandit/human_learning/debugging.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mexperiment_train()\n",
      "File \u001b[0;32m~/repos/gohr/bandit/human_learning/debug.py:408\u001b[0m, in \u001b[0;36mhl_model.experiment_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[39mprint\u001b[39m(player)\n\u001b[1;32m    407\u001b[0m \u001b[39m#print(\"Experience for player {}\".format(player))\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m creds,move_types \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplayer_train(player)\n\u001b[1;32m    409\u001b[0m melted_cred \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmelt(creds,[\u001b[39m'\u001b[39m\u001b[39mmove\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    410\u001b[0m melted_moves \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmelt(move_types,[\u001b[39m'\u001b[39m\u001b[39mmove\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/repos/gohr/bandit/human_learning/debug.py:352\u001b[0m, in \u001b[0;36mhl_model.player_train\u001b[0;34m(self, player)\u001b[0m\n\u001b[1;32m    348\u001b[0m best_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels[best]\n\u001b[1;32m    350\u001b[0m \u001b[39m# PROCESSING STAGE\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[39m# Process row through the environment module\u001b[39;00m\n\u001b[0;32m--> 352\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mprocess_row(row)\n\u001b[1;32m    353\u001b[0m \u001b[39m# Action is determined\u001b[39;00m\n\u001b[1;32m    354\u001b[0m action\u001b[39m=\u001b[39mrow\u001b[39m.\u001b[39mbucket\n",
      "File \u001b[0;32m~/repos/gohr/bandit/human_learning/debug.py:92\u001b[0m, in \u001b[0;36mProcessedEnv.process_row\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_row\u001b[39m(\u001b[39mself\u001b[39m,row):\n\u001b[1;32m     91\u001b[0m     \u001b[39m# Extract the x,y position of chosen piece, the chosen bucket, and current board\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     x \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39;49m\u001b[39mx\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m     93\u001b[0m     y \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     94\u001b[0m     bucket \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mbucket\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'x'"
     ]
    }
   ],
   "source": [
    "model.experiment_train()\n",
    "#display(model.main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>move</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   move variable  value\n",
       "0     1        1      3\n",
       "1     2        1      3\n",
       "2     3        1      3\n",
       "3     4        1      3\n",
       "4     5        1      3"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.melted_moves.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
