{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ruamel.yaml as yaml\n",
    "import os, sys ,re\n",
    "\n",
    "# Define yaml loader\n",
    "class SafeLoaderIgnoreUnknown(yaml.SafeLoader):\n",
    "    def ignore_unknown(self, node):\n",
    "        return None \n",
    "SafeLoaderIgnoreUnknown.add_constructor(None, SafeLoaderIgnoreUnknown.ignore_unknown)\n",
    "\n",
    "# Choose the runs to include in analysis\n",
    "#runs_to_analyze = [ {\"config\":\"naive_bs_as_n2\",\"nickname\":\"naive_dqn_bs_as_n2_2000_v1\"}]\n",
    "runs_to_analyze = [ {\"config\":\"naive_bs_as_n2\",\"nickname\":\"naive_dqn_bs_as_n2_2000_v1\"},\n",
    "                    {\"config\":\"naive_bs_as_n4\",\"nickname\":\"naive_dqn_bs_as_n4_2000_v1\"},\n",
    "                    {\"config\":\"naive_bs_as_n6\",\"nickname\":\"naive_dqn_bs_as_n6_2000_v1\"},\n",
    "                    {\"config\":\"naive_bs_as_n8\",\"nickname\":\"naive_dqn_bs_as_n8_2000_v1\"}]\n",
    "\n",
    "# Set relative path to data\n",
    "rule_runs_path = \"../active/outputs/rule_runs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function takes reward value per episode and calculates total moves, move accuracy, and whether the board was cleared\n",
    "def move_calculator(row,obj):\n",
    "    # Given a dataframe row, grab the reward value\n",
    "    reward = row['reward']\n",
    "    # Rewards default to negative\n",
    "    err = round(-1*reward)\n",
    "    # Separate cases for board being not cleared vs. cleared\n",
    "    # Episodes limited to 100 moves and board begins with fixed number of pieces, so more than 100-obj errors indicates that board was not cleared\n",
    "    if err > 100-obj: \n",
    "        move = 100\n",
    "        move_acc = (move-err)/move\n",
    "        cleared = 0\n",
    "    else:\n",
    "        move = err+obj\n",
    "        move_acc = obj/move\n",
    "        cleared = 1\n",
    "\n",
    "    return int(move), int(err), move_acc, int(cleared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all the runs\n",
    "for k in range(len(runs_to_analyze)):\n",
    "    # Create lists that will hold dataframes for concatenation\n",
    "    episode_df_list = []\n",
    "    move_df_list = []\n",
    "    terminal_results_list = []\n",
    "    # Form complete run path\n",
    "    run = runs_to_analyze[k][\"config\"]\n",
    "    nickname = runs_to_analyze[k][\"nickname\"]\n",
    "    run_path = rule_runs_path+run\n",
    "\n",
    "    # Get the experiments for that run (each one is a set of trials for a particular rule)\n",
    "    experiments = [name for name in os.listdir(run_path) if name!=\".DS_Store\"]\n",
    "   \n",
    "    # Loop over the experiments\n",
    "    for experiment in experiments:\n",
    "        # Get the neptune id\n",
    "        neptune_trial = experiment.split(\"_\")[0]\n",
    "        # String length may vary\n",
    "        trial_str_length = len(neptune_trial)\n",
    "        # Rule is everything after the neptune id and an _ character\n",
    "        rule_name = experiment[trial_str_length+1:]\n",
    "        \n",
    "        # Form complete experiment path\n",
    "        experiment_path = os.path.join(run_path,experiment)\n",
    "        # Get list of all trials\n",
    "        trials = [name for name in os.listdir(experiment_path) if name!=\".DS_Store\"]\n",
    "        # Sanity check the count (at least for the case where 56 is standard)\n",
    "        if not(len(trials)==56):\n",
    "            print(run, experiment, len(trials))\n",
    "\n",
    "        # Loop over all the trials\n",
    "        for trial in trials:\n",
    "            trial_path = os.path.join(experiment_path,trial)\n",
    "            # Get parameters\n",
    "            yaml_path = os.path.join(trial_path,\"data.yaml\")\n",
    "            with open(yaml_path, 'r') as param_file:\n",
    "                args = yaml.load(param_file, Loader=SafeLoaderIgnoreUnknown)\n",
    "                featurization =args[\"FEATURIZATION\"]\n",
    "                obj_count = args[\"INIT_OBJ_COUNT\"]\n",
    "\n",
    "            # Import episodic data and process relevant columns\n",
    "            episodic_data_path = os.path.join(trial_path,\"episode_data.csv\")\n",
    "            trial_results = pd.read_csv(episodic_data_path,index_col=0)\n",
    "\n",
    "            # Episode processing\n",
    "            # Old\n",
    "            # Formatting: nickname,rule_name,trial_id,board_id,number_of_pieces,number_of_moves,move_acc,if_clear\n",
    "            # New\n",
    "            # Formatting: number_of_moves,number_of_errors,if_cleared\n",
    "            # w/ header #.nickname,rule_name,trial_id\n",
    "            trial_results['nickname'] = nickname\n",
    "            trial_results[\"rule_name\"]=rule_name\n",
    "            trial_results['trial_id']=trial\n",
    "            trial_results['board_id']=trial_results['episode']\n",
    "            trial_results['number_of_pieces']=obj_count\n",
    "            trial_results[['number_of_moves','number_of_errors','move_acc','if_clear']]=trial_results.apply(move_calculator,args=(obj_count,),axis=1,result_type='expand')\n",
    "            \n",
    "            # Append results to a list for concatenation\n",
    "            episode_df_list.append(trial_results)\n",
    "\n",
    "    # Concatenate everything into one dataframe\n",
    "    episode_results_df = pd.concat(episode_df_list,ignore_index=True)\n",
    "    episode_results_df.sort_values(by=[\"rule_name\",\"trial_id\",\"board_id\"],inplace=True,ignore_index=True)\n",
    "    # Drop the original columns to arrive at final formatting\n",
    "    #episode_results_df.drop(labels=['episode','reward','nickname','rule_name','trial_id','board_id','number_of_pieces','move_acc'],axis=1,inplace=True)\n",
    "    result_path = 'mlc_proc_output/'+nickname\n",
    "    if not(os.path.exists(result_path)):\n",
    "        os.mkdir(result_path)\n",
    "    \n",
    "    header = \"#.nickname,rule_name,trial_id\\n#number_of_moves,number_of_errors,if_clear\\n\"\n",
    "    result_file = result_path+'/results.csv'\n",
    "    with open(result_file, 'w') as fp:\n",
    "        fp.write(header)\n",
    "\n",
    "    #episode_results_df.to_csv(result_path+'/results.csv',header=[\".\"+nickname,rule_name,\"0\"],index=False)\n",
    "    # Write out new episodic format\n",
    "    for rule in episode_results_df.rule_name.unique():\n",
    "        for trial in episode_results_df.query(\"rule_name==@rule\").trial_id.unique():\n",
    "            temp=episode_results_df.query(\"rule_name==@rule and trial_id==@trial\").copy()\n",
    "            temp.drop(labels=['episode','reward','nickname','rule_name','trial_id','board_id','number_of_pieces','move_acc'],axis=1,inplace=True)\n",
    "            temp=temp.astype('int')\n",
    "            temp.to_csv(result_file,header=['.'+nickname,rule,trial],mode='a',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
